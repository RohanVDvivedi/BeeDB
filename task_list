
 * define catalog tables and indexes on it - persistent
 * define lock tables and indexes on it - volatile
 * define transaction table and indexes on it - persistent
 * define statistics tables - persistent
 * define beedb struct
   * with pointer access to volatile memory using VolatilePageStore, and to shared persistent memory using MinTxEngine
   * using their corresponding page access methods and page modification methods
   * add data structures to get access for most relevant tuple definitions
 * define high level transaction struct consisteing of
   * 64 bit transactions id
   * last_mini_tx_id (id of the last mini transaction executed), last_logical_log_lsn (lsn of the last logical modification done)

 * implement query plan tree
   * with operators
 * implement relational algebra operators
   * selection -> filter with/without indexes
   * projection -> picking columns
   * sorting -> with/without indexes
   * joins -> with/without indexes
   * union, set difference and intersection

 * define layout for MVCC columns and figure out how to store multiple versions
 * define MVCC rules for different isolation levels

 * Design methodology
   * we will use postgresql architecture over mini transactions
   * we will have heaps (a future tuple indexer data structure) for storing tables, insert to which gives us a page_id (physical page_id) and a index (slot no) in that page
   * indexes will always include the page_id, slot_no in the index after the indexed columns and before the covering columns
   * inserts/deletes will always be done to all indexes and heaps in a single mini transaction
   * updates are just delete followed by insert
   * logical log is included in the commit message of mini transaction
     * above above points ensure that logical replication (in future) is done independently, allowing followers to have a different set of indexes
   * there will be vaccum, which will be thought off at the end of this project
   * header will include xmin, xmax, is_xmin_committed?, is_xmax_committed?
     * xmin, xmax will be 64 or lesser (atleast 48) bits wide
     * is_x***_committed? == 1, then x*** is surely committed, else we need to check if it is aborted or not

 * we need a heap table data structure like postgresql
   * use a bplus_tree (call it free space tree) to store keys for (free_space in bytes, page_id)
   * allocate a page and then update it in this free_space_tree
   * inserting a tuple gives you page_id, slot_no for locating the inserted tuple
     * loop to run iterator to find the page having enough free space
       * if found insert it there
     * else allocate a new page
       * keep on inserting into it until it is full
     * insert this page as a new entry
   * update/delete
     * directly work with the page_id, slot_no
   * above 2 operations require us to call restructuring of the heap table eventually, restructuring is done lazily
   * only restructuring and full table scan need the external lock
   * full table scan
     * shared_lock
     * for each tuple in free space tree
       * latch the page and read the tuple
     * shared_unlock
   * restructuring
     * exclusive_lock
     * for each tuple in free space tree
       * latch the page and get its free space
       * if empty discard it
       * if not same free space, then reinsert this entry
     * exclusive_unlock
     * everytime an insert, update or delete works with a page, it sets a bit in bloomfilter and incrementing a counter if the bloomfilter hasn't yet seen the page, once the counter reaches the threshold we run a restructuring job
   * we need the shared/exclusive lock only to prevent the scans to not re-read tuples or skip a set of tuples, due to concurrent inserts/updates or deletes
     * to avoid this we are using locks
     * instead of this lock we can also use an auxilary data structure that stores all active heap table pages, in a fixed order
     * this can be done by using a b+tree storing all page_ids in increasing order OR by using a bitmap index (yet to be implemented in TupleIndexer, probably using a page_table or array_table)
     * inserts/deletes and updates will now directly update the free space map tree
     * inserts and deletes that result into adding/removing a page from the heap will be the only thing that inserts/deleted the active heap table pages (along side the full table scan, that just reads it)
     * this can be done with a active heap pages b+tree OR a bitmap index (yet to be implemented in TupleIndexer)